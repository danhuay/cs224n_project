seed: 11711
use_gpu: true
cpu_workers: 0
batch_size: 8
epochs: 50
early_stop_patience: 10
learning_rate: 1.0e-5
need_testing: true

multitask_model_config:
  hidden_dropout_prob: 0.1
  hidden_size: 768

#fine_tune_mode: last-linear-layer
fine_tune_mode: full-model

train_data_tags:
  - para
  - sts
  - sst

supervised: true  # false for semi-supervised
aug_approach: back_translation  # completion | rnd_mask_completion

# training_approach: sequential
training_approach: simultaneous
mode: inference  # train | inference

tsa_schedule: linear # linear, exp, log, constant

train_data_loader_config:
  sst_filename: data/ids-sst-train.csv
  para_filename: data/quora-train-sample.csv
  sts_filename: data/sts-train.csv
  split: train
#  sample_frac:
#    sst: 1.0
#    para: 1.0
#    sts: 1.0
#    is_n_sample: false

#train_unsup_data_loader_config:
#  sst_filename: data/ids-sst-train.csv
#  para_filename: data/quora-train-sample.csv
#  sts_filename: data/sts-train.csv
#  split: train
#  n_sup_samples: 800
#  n_unsup_samples: 3200
#  n_sup_batch_size: 2
#  n_unsup_batch_size: 8
#  n_batches: 400
#  shuffle: true

dev_data_loader_config:
  sst_filename: data/ids-sst-dev.csv
  para_filename: data/quora-dev.csv
  sts_filename: data/sts-dev.csv
  split: dev

test_data_loader_config:
  sst_filename: data/ids-sst-test-student.csv
  para_filename: data/quora-test-student.csv
  sts_filename: data/sts-test-student.csv
  split: test

# model checkpoint files
model_checkpoint_path: models/{fine_tune_mode}-{epochs}-{lr}-multitask.pt
model_checkpoint_path_inference: "models/full-model-50-1e-05-multitask copy.pt"

# output files
dev_outputs:
  sst: predictions/sst-dev-output.csv
  para: predictions/para-dev-output.csv
  sts: predictions/sts-dev-output.csv

test_outputs:
  sst: predictions/sst-test-output.csv
  para: predictions/para-test-output.csv
  sts: predictions/sts-test-output.csv
